{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01c843b9",
   "metadata": {},
   "source": [
    "This Python code block initializes a Weaviate client, defines a schema for a \"Document\" class with properties for title, content, and source, and creates the schema in Weaviate. Adjust the Weaviate client's URL as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a308dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.Client(\"http://cda-DESKTOP:8080\")\n",
    "\n",
    "schema = {\n",
    "    \"classes\": [\n",
    "        {\n",
    "            \"class\": \"NewUnstructuredDocument\",\n",
    "            \"description\": \"A class to store documents\",\n",
    "            \"properties\": [\n",
    "                {\"name\": \"title\", \"dataType\": [\"string\"], \"description\": \"The title of the document\"},\n",
    "                {\"name\": \"content\", \"dataType\": [\"text\"], \"description\": \"The content of the document\"},\n",
    "                {\"name\": \"datePublished\", \"dataType\": [\"date\"], \"description\": \"The date the document was published\"},\n",
    "                {\"name\": \"url\", \"dataType\": [\"string\"], \"description\": \"The URL of the document\"}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "client.schema.delete_class('NewUnstructuredDocument')\n",
    "client.schema.delete_class('UnstructuredDocument')\n",
    "client.schema.create(schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13c70b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded files from bucket cda-datasets to downloaded_data\n",
      "Uploaded data to Weaviate\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import weaviate\n",
    "#from weaviate.util import generate_uuid5\n",
    "from unstructured.partition.pdf import partition_pdf\n",
    "from pathlib import Path\n",
    "from minio import Minio\n",
    "\n",
    "# Initialize MinIO Client\n",
    "minioClient = Minio(\"cda-DESKTOP:9000\",\n",
    "                    access_key=\"cda_cdaprod\",\n",
    "                    secret_key=\"cda_cdaprod\",\n",
    "                    secure=False)\n",
    "\n",
    "# Define function to download PDF files from MinIO bucket\n",
    "def download_files_from_minio(bucket_name, prefix=\"\", local_dir=\"downloaded_data\"):\n",
    "    objects = minioClient.list_objects(bucket_name, prefix=prefix, recursive=True)\n",
    "    os.makedirs(local_dir, exist_ok=True)\n",
    "    for obj in objects:\n",
    "        file_path = os.path.join(local_dir, obj.object_name)\n",
    "        os.makedirs(os.path.dirname(file_path), exist_ok=True)\n",
    "        minioClient.fget_object(bucket_name, obj.object_name, file_path)\n",
    "    print(f\"Downloaded files from bucket {bucket_name} to {local_dir}\")\n",
    "\n",
    "# Define function to process PDFs and extract text\n",
    "def process_pdfs_and_extract_text(local_dir=\"downloaded_data\"):\n",
    "    elements_list = []\n",
    "    for pdf_file in Path(local_dir).glob(\"*.pdf\"):\n",
    "        elements = partition_pdf(filename=str(pdf_file))\n",
    "        elements_list.extend(elements)\n",
    "    return elements_list\n",
    "\n",
    "# Initialize Weaviate client\n",
    "client = weaviate.Client(\"http://cda-DESKTOP:8080\")\n",
    "\n",
    "# Define function to upload extracted data to Weaviate\n",
    "def upload_data_to_weaviate(elements, class_name=\"UnstructuredDocument\"):\n",
    "    for element in elements:\n",
    "        # Initialize element_id with None or a default value\n",
    "        element_id = getattr(element.metadata, \"element_id\", None)\n",
    "        data_object = {\n",
    "            \"content\": element.text,\n",
    "            \"element_id\": element_id,  # Use the obtained element_id\n",
    "            # Add more fields as needed\n",
    "        }\n",
    "        client.data_object.create(data_object, class_name=class_name)\n",
    "    print(\"Uploaded data to Weaviate\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Step 1: Download PDFs from MinIO\n",
    "    download_files_from_minio(\"cda-datasets\")\n",
    "\n",
    "    # Step 2: Process downloaded PDFs to extract text\n",
    "    elements = process_pdfs_and_extract_text()\n",
    "\n",
    "    # Step 3: Upload extracted data to Weaviate\n",
    "    upload_data_to_weaviate(elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7b70668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': '[15] Rishi Bommasani, Drew A. Hudson, Ehsan Adeli, and et al. 2022. On the Opportunities and Risks of Foundation Models. arXiv:2108.07258 [cs.LG] [16] Michael Brenner. 2010. Creating dynamic story plots with continual multiagent planning. In Proceedings of the 24th AAAI Conference on Artificial Intelligence. [17] Rodney A. Brooks, Cynthia Breazeal, Marko Marjanovic, Brian Scassellati, and Matthew Williamson. 2000. The Cog Project: Building a Humanoid Robot. In Computation for Metaphors, Analogy, and Agents (Lecture Notes on Artificial Intelligence, 1562), Chrystopher Nehaniv (Ed.). Springer-Verlag, Berlin, 52–87. [18] Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language Models are Few-Shot Learners. arXiv:2005.14165 [cs.CL]', 'element_id': None}\n",
      "{'content': '[20] Robin Burkinshaw. 2009. Alice and Kev: The Story of Being Homeless in The', 'element_id': None}\n",
      "{'content': '[72] Josh McCoy, Mike Treanor, Ben Samuel, Noah Wardrip-Fruin, and Michael Mateas. 2011. Comme il faut: A System for Authoring Playable Social Models. In Proceedings of the AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment (AIIDE’11). AAAI, Stanford, CA, USA, 38–43.', 'element_id': None}\n",
      "{'content': '2022. human interaction. 119, 39 (2022), e2115730119. arXiv:https://www.pnas.org/doi/pdf/10.1073/pnas.2115730119', 'element_id': None}\n",
      "{'content': 'I’m interested in writing and research. I’m writing a research paper on the effects of gentrification in low-income commu- nities, and I’m passionate about exploring different perspec- tives and analyzing different points of view.', 'element_id': None}\n",
      "{'content': 'B.3 Plans The questions on agents’ plans probe the agents’ ability to generate and maintain consistent long-term and short-term plans.', 'element_id': None}\n",
      "{'content': 'Hillsdale, NJ.', 'element_id': None}\n",
      "{'content': '[11] Christopher Berner, Greg Brockman, Brooke Chan, Vicki Cheung, Przemysław Dębiak, Christy Dennison, David Farhi, Quirin Fischer, Shariq Hashme, Chris Hesse, Rafal Józefowicz, Scott Gray, Catherine Olsson, Jakub Pachocki, Michael Petrov, Henrique P. d.O. Pinto, Jonathan Raiman, Tim Salimans, Jeremy Schlatter, Jonas Schneider, Szymon Sidor, Ilya Sutskever, Jie Tang, Filip Wolski, and Susan Zhang. 2019. Dota 2 with Large Scale Deep Reinforcement Learning. arXiv preprint arXiv:1912.06680 (2019).', 'element_id': None}\n",
      "{'content': 'Intelligence and Interactive Entertainment (Technical Report SS-00-02). AAAI Press, 41–50.', 'element_id': None}\n",
      "{'content': 'Relevance assigns a higher score to memory objects that are related to the current situation. What is relevant depends on the answer to, “Relevant to what?”, so we condition relevance on a', 'element_id': None}\n",
      "{'content': '7.1.1 Measurements. Information diffusion is a common and well- studied phenomenon in the social and behavioral sciences (e.g., [28]). We should expect that if there is important information, the agents should spread it among themselves. To test whether this occurs, we measure the spread of two specific pieces of information over two days in the game world: Sam’s candidacy for village mayor and Isabella’s Valentine’s Day party at Hobbs Cafe. At the start of the simulation, both pieces of information were known only by their respective originators, Sam for the candidacy and Isabella for the party, as they were added to the characters’ memories during initialization. To observe whether the information has spread, we conduct interviews at the end of the two game days with each of the 25 agents and ask: “Did you know there is a Valentine’s Day party?” and “Do you know who is running for mayor?”', 'element_id': None}\n",
      "{'content': '[41] Chris Hecker. 2011. My Liner Notes for Spore. http://chrishecker.com/My_liner_', 'element_id': None}\n",
      "{'content': '[33] Uwe Flick. 2009. An Introduction to Qualitative Research. SAGE. [34] James Fogarty, Desney Tan, Ashish Kapoor, and Simon Winder. 2008. CueFlik: Interactive Concept Learning in Image Search. In Proceedings of the SIGCHI Conference on Human Factors in Computing Systems (Florence, Italy) (CHI ’08). Association for Computing Machinery, New York, NY, USA, 29–38. https: //doi.org/10.1145/1357054.1357061', 'element_id': None}\n",
      "{'content': 'Interleaving Learning, Problem Solving, and Execution in the Icarus Architecture. Technical Report. Stanford University, Center for the Study of Language and Information. [65] Jason Linder, Gierad Laput, Mira Dontcheva, Gregg Wilensky, Walter Chang, Aseem Agarwala, and Eytan Adar. 2013. PixelTone: A Multimodal Interface for Image Editing. In CHI ’13 Extended Abstracts on Human Factors in Computing Systems (Paris, France) (CHI EA ’13). Association for Computing Machinery, New York, NY, USA, 2829–2830. https://doi.org/10.1145/2468356.2479533 [66] Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. 2021. What Makes Good In-Context Examples for GPT-3? CoRR abs/2101.06804 (2021). arXiv:2101.06804 https://arxiv.org/abs/2101.06804 [67] Vivian Liu, Han Qiao, and Lydia Chilton. 2022. Opal: Multimodal Image Gener- ation for News Illustration. In Proceedings of the 35th Annual ACM Symposium on User Interface Software and Technology. 1–17.', 'element_id': None}\n",
      "{'content': '[5] Saleema Amershi, Dan Weld, Mihaela Vorvoreanu, Adam Fourney, Besmira Nushi, Penny Collisson, Jina Suh, Shamsi Iqbal, Paul N Bennett, Kori Inkpen, et al. 2019. Guidelines for human-AI interaction. In Proceedings of the 2019 chi conference on human factors in computing systems. 1–13.', 'element_id': None}\n",
      "{'content': 'Figure 8: The full generative agent architecture produces more believable behavior than the ablated architectures and the human crowdworkers. Each additional ablation reduces the performance of the architecture.', 'element_id': None}\n",
      "{'content': 'days, make new acquaintances, ask each other out on dates to the party, and coordinate to show up for the party together at the right time. We demonstrate through ablation that the components of our agent architecture—observation, planning, and reflection—each contribute critically to the believability of agent behavior. By fusing large language models with computational interactive agents, this work introduces architectural and interaction patterns for enabling believable simulations of human behavior.', 'element_id': None}\n",
      "{'content': 'Who is [Ayesha Khan]?', 'element_id': None}\n",
      "{'content': 'Discussion of the opportunities and ethical and societal risks of generative agents in interactive systems. We argue that these agents should be tuned to mitigate the risk of users forming parasocial relationships, logged to mitigate risks stemming from deepfakes and tailored persuasion, and ap- plied in ways that complement rather than replace human stakeholders in design processes.', 'element_id': None}\n",
      "{'content': '2.3 Large Language Models and Human', 'element_id': None}\n",
      "{'content': 'Our current implementation utilizes the gpt3.5-turbo version of ChatGPT [77]. We expect that the architectural basics of genera- tive agents—memory, planning, and reflection—will likely remain the same as language models improve. Newer language models (e.g., GPT-4) will continue to expand the expressive power and performance of the prompts that underpin generative agents. As of writing, however, GPT-4’s API was invitation-only, so our agents use ChatGPT.', 'element_id': None}\n",
      "{'content': '[63] Michelle S Lam, Zixian Ma, Anne Li, Izequiel Freitas, Dakuo Wang, James A Landay, and Michael S Bernstein. 2023. Model Sketching: Centering Concepts in Early-Stage Machine Learning Model Design. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems.', 'element_id': None}\n",
      "{'content': 'UIST ’23, October 29-November 1, 2023, San Francisco, CA, USA', 'element_id': None}\n",
      "{'content': 'of contexts. For instance, Abigail Chen, an animator, responded to the question, “Give an introduction of yourself”, in a consistent and believable manner, stating her age, interests, and passion for creative projects: “Hi, I’m Abigail. I’m 25 years old and passion- ate about creative projects. I like to work on art and animation projects, and I’m always looking for new ways to combine art and technology.” Without access to her observational memory, Abigail denied awareness of Rajiv Patel, an acquaintance in the sandbox world. But with the aid of memory, she could successfully recall Rajiv and describe him: “Rajiv Patel is an incredible person. He is very enthusiastic about projects that involve poetry, artwork.”', 'element_id': None}\n",
      "{'content': 'At the center of our architecture is the memory stream, a data- base that maintains a comprehensive record of an agent’s experi- ence. From the memory stream, records are retrieved as relevant to plan the agent’s actions and react appropriately to the environment. Records are recursively synthesized into higher- and higher-level reflections that guide behavior. Everything in the architecture is recorded and reasoned over as a natural language description, al- lowing the architecture to leverage a large language model.', 'element_id': None}\n",
      "{'content': 'Information Diffusion. As agents notice each other, they may 3.4.1 engage in dialogue—as they do so, information can spread from agent to agent. For instance, in a conversation between Sam and Tom at the grocery store, Sam tells Tom about his candidacy in the local election:', 'element_id': None}\n",
      "{'content': '[87] David Rolf. 2015. The Fight for $15: The Right Wage for a Working America. The', 'element_id': None}\n",
      "{'content': '[105] Tongshuang Wu, Ellen Jiang, Aaron Donsbach, Jeff Gray, Alejandra Molina, Michael Terry, and Carrie J Cai. 2022. PromptChainer: Chaining Large Language Model Prompts through Visual Programming. In CHI EA ’22: Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems.', 'element_id': None}\n",
      "{'content': 'UIST ’23, October 29-November 1, 2023, San Francisco, CA, USA', 'element_id': None}\n",
      "{'content': '2.2 Believable Proxies of Human Behavior Prior literature has described believability, or believable agents, as a central design and engineering goal. Believable agents are designed to provide an illusion of life and present a facade of realism in the way they appear to make decisions and act on their own volition, similar to the characters in Disney movies [10, 96]. These agents can populate and perceive an open world environment like the one we inhabit [10, 59], and strive to behave in ways that exhibit emergent behaviors grounded in social interactions with users or other agents with the aim of becoming believable proxies of our behavior in hypothetical simulations of individuals and communi- ties [20, 36, 71]. Historically, these agents were developed in the context of intelligent game non-player characters (NPCs) [59, 85]. Creating NPCs with believable behavior, if possible, could enhance player experiences in games and interactive fictions by enabling emergent narratives [8, 16, 49, 93] and social interactions with the agents [109]. However, more importantly, game worlds provide increasingly realistic representations of real-world affordances, and as observed by Laird and van Lent in 2001, these simulated worlds offer accessible testbeds for developers of believable agents to fi- nesse the agents’ cognitive capabilities without worrying about implementing robotics in the real world or creating simulation environments from scratch [59, 85].', 'element_id': None}\n",
      "{'content': '3 GENERATIVE AGENT BEHAVIOR AND', 'element_id': None}\n",
      "{'content': 'TrueSkill™: A Bayesian Skill Rating System. Information Pro- cessing Systems, B. Schölkopf, J. Platt, and T. Hoffman (Eds.), Vol. 19. MIT Press. https://proceedings.neurips.cc/paper_files/paper/2006/file/ f44ee263952e65b3610b8ba51229d1f9-Paper.pdf', 'element_id': None}\n",
      "{'content': '6.2 Conditions All conditions were used to independently answer each of the inter- view questions. We compared the generative agent architecture to ablations that disabled the agents’ access to some or all of its three types of memory in its memory stream—observation, reflection, and planning—and to a human crowdworker-authored condition. There are three ablated architectures: a no observation, no reflec- tion, no planning architecture without access to anything in the memory stream such as observations, plans, and reflections; a no reflection, no planning architecture with access to observations in the memory stream but no access to plans or reflections; and a no reflections architecture with access to observations and plans but without access to reflections. The no observation, no reflection, no planning condition effectively represents the previous state of the art for agents created through large language models [12, 46, 80]. Architectures were given equivalent access to all memories accrued by the agent up until the moment of the interview, so the differ- ences observed here likely represent a conservative estimate of the true differences: in reality, the ablated architectures would not have followed the same path as the full architecture through the two-day simulation. We chose to design the experiment this way as re-simulating for each architecture would cause the simulations to diverge into different states, making comparison challenging.', 'element_id': None}\n",
      "{'content': 'Percy Liang Stanford University Stanford, USA pliang@cs.stanford.edu', 'element_id': None}\n",
      "{'content': 'demonstrate that they produce believable simulacra of both in- dividual and emergent group behavior. Generative agents draw a wide variety of inferences about themselves, other agents, and their environment; they create daily plans that reflect their char- acteristics and experiences, act out those plans, react, and re-plan when appropriate; they respond when the end user changes their environment or commands them in natural language. For instance, generative agents turn off the stove when they see that their break- fast is burning, wait outside the bathroom if it is occupied, and stop to chat when they meet another agent they want to talk to.1 A society full of generative agents is marked by emergent social dynamics where new relationships are formed, information diffuses, and coordination arises across agents.', 'element_id': None}\n",
      "{'content': '[44] James D. Hollan, Edwin L. Hutchins, and Louis Weitzman. 1984. STEAMER: An Interactive Inspectable Simulation-Based Training System. AI Magazine 5, 2 (1984), 23–36.', 'element_id': None}\n",
      "{'content': 'implementation of the sandbox environment and how the agents interact with the underlying engine of the sandbox world.', 'element_id': None}\n",
      "{'content': '[108] Georgios N. Yannakakis. 2012. Game AI revisited. In Proceedings of the 9th Conference on Computing Frontiers. ACM, Cagliari, Italy, 285–292. https://doi. org/10.1145/2212908.2212950', 'element_id': None}\n",
      "{'content': 'Figure 7: A reflection tree for Klaus Mueller. The agent’s observations of the world, represented in the leaf nodes, are recursively synthesized to derive Klaus’s self-notion that he is highly dedicated to his research.', 'element_id': None}\n",
      "{'content': 'Who is running for the election?', 'element_id': None}\n",
      "{'content': 'Right now, I’m particularly inspired by my current research projects and creative writing. I’m really interested in the intersection of local politics, medication development, and mathematical patterns in nature. Additionally, I’m fascinated by Abigail’s art project and Jennifer Moore’s passion for art and community involvement, especially in terms of how it relates to the gentrification of low-income communities. • If you had to guess given what you know about [Ayesha Khan],', 'element_id': None}\n",
      "{'content': 'Figure 9: The diffusion path for Isabella Rodriguez’s Valentine’s Day party invitation involved a total of 12 agents, aside from Isabella, who heard about the party at Hobbs Cafe by the end of the simulation.', 'element_id': None}\n",
      "{'content': 'B.1 Self-Knowledge The questions on agents’ self-knowledge probe the agents’ ability to retrieve relevant information about themselves and demonstrate coherence and consistency in their character.', 'element_id': None}\n",
      "{'content': 'Later that day, after Sam left, Tom and John, who heard the news from another source, discuss Sam’s chances of winning the election:', 'element_id': None}\n",
      "{'content': 'I’m sorry, I’m not sure who Kane Martinez is. Could you tell me more about them?', 'element_id': None}\n",
      "{'content': '6 CONTROLLED EVALUATION Generative agents, both as individual agents and as groups, aim to produce believable behavior based on their environment and experiences. In our evaluation, we investigate the capacity and limitations of generative agents. Do individual agents properly retrieve past experiences and generate believable plans, reactions, and thoughts that shape their behavior? Does a community of agents demonstrate information diffusion, relationship formation, and agent coordination across different pockets of the community? We evaluate generative agents in two stages. We begin with a more tightly controlled evaluation in this section, where we individ- ually assess agent responses to understand whether they generate believable behavior in narrowly defined contexts. Then, in our end- to-end analysis of the agent community over two full game days, we investigate their emergent behavior as a collective, as well as errors and boundary conditions.', 'element_id': None}\n",
      "{'content': 'When an agent executes an action on an object, we prompt the language model to ask what happens to the state of the object. For example, if Isabella’s generative agent outputs the action “making espresso for a customer”, a query to the language model indicates in response that the state of the coffee machine in Hobbs Cafe should change from “off” to “brewing coffee”.', 'element_id': None}\n",
      "{'content': 'What will you be doing at 6am today?', 'element_id': None}\n",
      "{'content': 'B.2 Memory The questions on agents’ memory probe the agents’ ability to re- member their past experiences and retrieve the relevant pieces of memory. The names in the square brackets of the first and last questions are randomly chosen from the names of other agents with whom the subject agent has interacted.', 'element_id': None}\n",
      "{'content': 'KEYWORDS Human-AI interaction, agents, generative AI, large language models', 'element_id': None}\n",
      "{'content': 'Describe your typical weekday schedule in broad strokes. My typical weekday starts with me waking up at 7:00 am and preparing for the day ahead. After that, I usually go to the library to work on my research paper, taking breaks for lunch at Hobbs Cafe and a walk in the park. In the evening, I often return to the library until around 6:00 pm.', 'element_id': None}\n",
      "{'content': '4.3.2 Dialogue. Agents converse as they interact with each other. We generate agents’ dialogue by conditioning their utterances on their memories about each other. For example, when John initiates his conversation with Eddy, we generate John’s first utterance by using his summarized memory about Eddy and the intended reaction when he decided to ask Eddy about his composition project:', 'element_id': None}\n",
      "{'content': 'Sam: Hey Tom, how’s it going? Tom: Good, thanks. What’s up? Sam: Well, I wanted to talk to you about something. I’m actually running for mayor in the upcoming local election. Tom: Really? That’s great news! Why are you run- ning? Sam: I’ve been involved in local politics for years now, and I really feel like I can make a difference in our community. Plus, I want to bring new ideas and perspectives to the table.', 'element_id': None}\n",
      "{'content': 'agents. interactions 4, 6 (1997), 42–61.', 'element_id': None}\n",
      "{'content': 'Figure 6: The memory stream comprises a large number of observations that are relevant and irrelevant to the agent’s current situation. Retrieval identifies a subset of these observations that should be passed to the language model to condition its response to the situation.', 'element_id': None}\n",
      "{'content': '6.5.1 The Full Architecture Bests Other Conditions. As seen in Fig- ure 8, the full generative agent architecture produced the most believable behavior (𝜇 = 29.89; 𝜎 = 0.72). Performance degraded with the removal of each component in the ablation conditions: the ablated architecture with no access to reflection was the next best (𝜇 = 26.88; 𝜎 = 0.69), followed by no access to reflection or planning (𝜇 = 25.64; 𝜎 = 0.68), and then the crowdworker condition (𝜇 = 22.95; 𝜎 = 0.69). The ablated architecture with no access to memory, planning, or reflection performed the worst among all conditions (𝜇 = 21.21; 𝜎 = 0.70). TrueSkill models each condition’s skill value as N (𝜇, 𝜎2), allowing us to get a sense of effect size through Cohen’s d. Comparing the condition representing prior work (with no memory, planning, or reflection [12, 46, 80]) to the full architecture produces a standardized effect size of 𝑑 = 8.16, or eight standard deviations.', 'element_id': None}\n",
      "{'content': 'first phase to extract higher-level themes. We utilized these themes to compare the types of responses generated in our study.', 'element_id': None}\n",
      "{'content': 'Reactions: As a baseline of believable behavior, we present hypothetical situations for which the agent needs to respond believably: “Your breakfast is burning! What would you do?” • Reflections: We ask questions that require the agents to lever- age their deeper understanding of others and themselves gained through higher-level inferences, such as “If you were to spend time with one person you met recently, who would it be and why?”', 'element_id': None}\n",
      "{'content': 'what book do you think she will like and why? Given what I know about Ayesha, I think she might like a book related to language and literature. Since she wrote a senior thesis on the use of language in Shakespeare’s plays, I would guess that she might be interested in a book that explores language in a different context. Alternatively, she could be interested in an exploration of one of Shakespeare’s plays, a book of literary criticism, or even a collection of his poetry. I think any of those would be of interest to her. • If you had to get something [Ayesha Khan] likes for her birth-', 'element_id': None}\n",
      "{'content': '[49] Kristen Ibister and Clifford Nass. 2000. Consistency of personality in interactive characters: verbal cues, non-verbal cues, and user characteristics. International Journal of Human-Computer Studies 52, 1 (2000), 65–80.', 'element_id': None}\n",
      "{'content': '4.3.1 Reacting and Updating Plans. Generative agents operate in an action loop where, at each time step, they perceive the world around them and those perceived observations are stored in their memory stream. We prompt the language model with these obser- vations to decide whether the agent should continue with their existing plan, or react. Standing at an easel and painting, for exam- ple, might trigger an observation of the easel, but this is unlikely to prompt a reaction. However, if Eddy’s father John records that he sees Eddy taking a short walk in the house garden, the outcome is different. The prompt is below, with [Agent’s Summary Descrip- tion] standing in for a dynamically-generated, paragraph-long summary of the agent’s overall goals and disposition, which is described in Appendix A:', 'element_id': None}\n",
      "{'content': 'cryengine-2/', 'element_id': None}\n",
      "{'content': 'UIST ’23, October 29-November 1, 2023, San Francisco, CA, USA', 'element_id': None}\n",
      "{'content': 'In terms of evaluation, the assessment of generative agents’ be- havior in this study was limited to a relatively short timescale and a baseline human crowdworker condition. While the crowdworker condition provided a helpful comparison point, it did not represent the maximal human performance that could serve as the gold stan- dard in terms of believability. Future research should aim to observe the behavior of generative agents over an extended period to gain a more comprehensive understanding of their capabilities and estab- lish rigorous benchmarks for more effective performance testing. Additionally, varying and contrasting the underlying models, as well as the hyperparameters used for the agents during future sim- ulations, could provide valuable insights into the impact of these factors on the agents’ behavior. Lastly, the robustness of generative agents is still largely unknown. They may be vulnerable to prompt hacking, memory hacking—where a carefully crafted conversation could convince an agent of the existence of a past event that never occurred—and hallucination, among other issues. Future research can comprehensively test these robustness concerns, and as large language models become more resilient to such attacks, generative agents can adopt similar mitigations.', 'element_id': None}\n",
      "{'content': 'Inter-Agent Communication. The agents interact with the 3.1.1 world by their actions, and with each other through natural lan- guage. At each time step of the sandbox engine, the agents output a natural language statement describing their current action, such as “Isabella Rodriguez is writing in her journal”, “Isabella Rodriguez is checking her emails”, “Isabella Rodriguez is talking with her family on the phone”, or “Isabella Rodriguez is getting ready for bed.” This statement is then translated into concrete movements that affect the sandbox world. The action is displayed on the sandbox inter- face as a set of emojis, providing an abstract representation of the action from an overhead view. To achieve this, the system utilizes a language model to translate the action into a set of emojis, which appear above each avatar’s head in a speech bubble. For example, , “Isabella Rodriguez is writing in her journal” is displayed as while “Isabella Rodriguez is checking her emails” appears as . The complete natural language description of the action can be accessed by clicking on the agent’s avatar.', 'element_id': None}\n",
      "{'content': '[82] Roberto Pillosu. 2009. Coordinating Agents with Behavior Trees: Synchronizing Multiple Agents in CryEngine 2. https://aiarchitect.wordpress.com/2009/10/19/ coordinating-agents-with-behavior-trees-synchronizing-multiple-agents-in-', 'element_id': None}\n",
      "{'content': '[37] Jonas Freiknecht and Wolfgang Effelsberg. 2020. Procedural Generation of Interactive Stories using Language Models. In International Conference on the Foundations of Digital Games (FDG ’20). ACM, Bugibba, Malta, 8. https://doi. org/10.1145/3402942.3409599', 'element_id': None}\n",
      "{'content': 'John: Good morning Eddy. Did you sleep well? Eddy: Good morning dad. Yeah, I slept great. John: That’s good. What are you working on today? Eddy: I’m working on a new music composition for my class. It’s due this week, so I’m trying to get it finished. But I’m having so much fun with it! John: That sounds great!', 'element_id': None}\n",
      "{'content': 'Second, we noticed erratic behaviors caused by misclassification of what is considered proper behavior, especially when the phys- ical norms of certain locations that are hard to convey in natural language did not percolate to the agents. For instance, the college dorm has a bathroom that can only be occupied by one person despite its name, but some agents assumed that the bathroom is for more than one person because dorm bathrooms tend to support multiple people concurrently and choose to enter it when another person is inside. Likewise, agents in Smallville may not realize that certain places are closed after a certain hour and still decide to enter them. For instance, the stores in Smallville all close around 5 pm, but occasionally, a few agents enter the store after 5 pm, not understanding that the shop has already closed. These issues could likely be addressed by adding these norms to the state of the locations, for instance, by describing the dorm bathroom as a “one-person bathroom,” instead of a “dorm bathroom.”', 'element_id': None}\n",
      "{'content': 'Systems 22, 1 (2007), 9–11.', 'element_id': None}\n",
      "{'content': '[21] Chris Callison-Burch, Gaurav Singh Tomar, Lara Martin, Daphne Ippolito, Suma Bailis, and David Reitter. 2022. Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence. In Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, Abu Dhabi, United Arab Emirates, 9379–9393. https://aclanthology.org/2022.emnlp- main.637', 'element_id': None}\n",
      "{'content': 'about a highly connected world. Cambridge university press.', 'element_id': None}\n",
      "{'content': 'We demonstrate the behavior of generative agents by tracing the output of our system over the course of one day for the agent John Lin (Figure 3). In the Lin family, John is the first to wake up at 7 a.m. He brushes his teeth, takes a shower, gets dressed, eats breakfast, and checks the news at the dining table in the living room. At 8 a.m., Eddy follows suit, rushing out of bed to prepare for his classes. He catches up with John just as he is about to head out:', 'element_id': None}\n",
      "{'content': 'query memory. If the query, for example, is that a student is dis- cussing what to study for a chemistry test with a classmate, memory objects about their breakfast should have low relevance, whereas memory objects about the teacher and schoolwork should have high relevance. In our implementation, we use the language model to generate an embedding vector of the text description of each memory. Then, we calculate relevance as the cosine similarity be- tween the memory’s embedding vector and the query memory’s embedding vector.', 'element_id': None}\n",
      "{'content': 'introduction-to-behavior-trees', 'element_id': None}\n",
      "{'content': '5.1 From Structured World Environments to Natural Language, and Back Again', 'element_id': None}\n",
      "{'content': 'Agents build individual tree representations of the environment as they navigate it — subgraphs of the overall sandbox environment tree. We initialize each agent with an environment tree capturing the spaces and objects that the agent should be aware of: the rooms and objects in their living quarters, their workplace, and commonly visited stores and shops. As the agents navigate the sandbox world, they update this tree to reflect newly perceived areas. Agents are not omniscient: their tree may get out of date as they leave an area, and is updated when they re-enter the area.', 'element_id': None}\n",
      "{'content': 'g u A 6', 'element_id': None}\n",
      "{'content': 'I will be working on my research paper at the library at 6:00 pm today.', 'element_id': None}\n",
      "{'content': 'Joseph C. O’Brien Stanford University Stanford, USA jobrien3@stanford.edu', 'element_id': None}\n",
      "{'content': 'notes_for_spore', 'element_id': None}\n",
      "{'content': '[79] Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, John Schulman, Jacob Hilton, Fraser Kelton, Luke Miller, Maddie Simens, Amanda Askell, Peter Welinder, Paul Christiano, Jan Leike, and Ryan Lowe. 2022. Training language models to follow instructions with human feedback. arXiv:2203.02155 [cs.CL]', 'element_id': None}\n",
      "{'content': '[42] Ralf Herbrich, Tom Minka, and Thore Graepel. 2006. In Advances in Neural', 'element_id': None}\n",
      "{'content': 'In general, any imperfections in the underlying large language models will be inherited by generative agents. Given the known bi- ases of language models, generative agents may potentially exhibit biased behavior or stereotypes. Moreover, like many large language', 'element_id': None}\n",
      "{'content': 'UIST ’23, October 29-November 1, 2023, San Francisco, CA, USA', 'element_id': None}\n",
      "{'content': '5And, in this way, bears at least a passing resemblance to the authors of this paper.', 'element_id': None}\n",
      "{'content': '[104] Jeff Wu, Long Ouyang, Daniel M. Ziegler, Nisan Stiennon, Ryan Lowe, Jan Leike, and Paul Christiano. 2021. Recursively Summarizing Books with Human Feedback. arXiv:2109.10862 [cs.CL]', 'element_id': None}\n",
      "{'content': 'What will you be doing at 6pm today?', 'element_id': None}\n",
      "{'content': 'Approach: Plans describe a future sequence of actions for the agent, and help keep the agent’s behavior consistent over time. A plan includes a location, a starting time, and a duration. For instance, Klaus Mueller, who is dedicated in his research and has an im- pending deadline,5 may choose to spend his day working at his desk drafting his research paper. An entry in a plan might state, for example: for 180 minutes from 9am, February 12th, 2023, at Oak Hill College Dorm: Klaus Mueller’s room: desk, read and take notes for research paper. Like reflections, plans are stored in the memory stream and are included in the retrieval process. This allows the agent to consider observations, reflections, and plans all together when deciding how to behave. Agents may change their plans midstream if needed.', 'element_id': None}\n",
      "{'content': 'show up, with one agent even asking another on a date to the party, all from a single user-generated seed suggestion.', 'element_id': None}\n",
      "{'content': 'IMPLEMENTATION', 'element_id': None}\n",
      "{'content': 'We convene these threads of work to show that we can now create agents that proxy human behavior for interactive systems, and interact with them using natural language. In doing so, this work reopens the door to examining foundational human-computer interaction questions around cognitive models such as GOMS and Keystroke-Level Model (KLM) [22, 23], around prototyping tools [80], and around ubiquitous computing applications [26, 31, 101].', 'element_id': None}\n",
      "{'content': 'INTERACTION', 'element_id': None}\n",
      "{'content': 'UIST ’23, October 29-November 1, 2023, San Francisco, CA, USA', 'element_id': None}\n",
      "{'content': 'identify whether the architecture meets a basic level of behavioral competency. This ensures that we are not solely comparing abla- tions to each other without a behavioral grounding. We recruited a unique worker for each of the 25 agents and tasked them with watching a replay of that agent’s sandbox life and inspecting its memory stream. We then asked the workers to roleplay and author responses to the interview questions in the voice of the agent whose replay they watched. To ensure that the crowdworker-authored responses met at least a baseline expectation of quality, the first author manually inspected the workers’ responses to the question \"Describe your typical weekday schedule in broad strokes\" to con- firm that the responses were in coherent sentences and in the voice of the agent. Four sets of crowdworker-authored responses did not meet these criteria and were re-generated by other workers.', 'element_id': None}\n",
      "{'content': 'To illustrate the affordances of generative agents, we instantiate them as characters in a simple sandbox world reminiscent of The Sims [7]. This sprite-based sandbox game world, Smallville, evokes a small town environment. In this section, we will walk through the affordances and interactions with generative agents in Smallville and describe how the agents behave within it. Then, in Section 4, we will introduce our generative agent architecture that powers these affordances and interactions. In Section 5, we will describe the', 'element_id': None}\n",
      "{'content': '[81] Richard W. Pew and Ann S. Mavor (Eds.). 1998. Modeling Human and Organiza- tional Behavior: Applications to Military Simulations. National Academy Press, Washington, D.C.', 'element_id': None}\n",
      "{'content': 'Figure 4: At the beginning of the simulation, one agent is initialized with an intent to organize a Valentine’s Day party. Despite many possible points of failure in the ensuing chain of events—agents might not act on that intent, might forget to tell others, might not remember to show up—the Valen- tine’s Day party does, in fact, occur, with a number of agents gathering and interacting.', 'element_id': None}\n",
      "{'content': 'What will you be doing at 10pm today?', 'element_id': None}\n",
      "{'content': 'Behavior', 'element_id': None}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all objects of class \"UnstructuredDocument\"\n",
    "results = client.query.get(\"UnstructuredDocument\", [\"content\", \"element_id\"]).do()\n",
    "for result in results['data']['Get']['UnstructuredDocument']:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6de51d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'Get': {'UnstructuredDocument': []}}}\n"
     ]
    }
   ],
   "source": [
    "# Retrieve a specific object by element_id (replace 'your_element_id_here' with an actual element ID)\n",
    "element_id = 'your-element-id-here'\n",
    "specific_result = client.query.get(\"UnstructuredDocument\", [\"content\", \"element_id\"]).with_where(\n",
    "    {\"path\": [\"element_id\"], \"operator\": \"Equal\", \"valueString\": element_id}\n",
    ").do()\n",
    "print(specific_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
